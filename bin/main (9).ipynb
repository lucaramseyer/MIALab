{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb31522-ff8b-46b7-96b0-348b8515da53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A medical image analysis pipeline.\n",
    "\n",
    "The pipeline is used for brain tissue segmentation using a decision forest classifier.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e525c-5d9b-4d85-a15a-082750bb7bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "import warnings\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import sklearn.ensemble as sk_ensemble\n",
    "import numpy as np\n",
    "import pymia.data.conversion as conversion\n",
    "import pymia.evaluation.writer as writer\n",
    "\n",
    "sys.argv = ['']\n",
    "\n",
    "try:\n",
    "    import mialab.data.structure as structure\n",
    "    import mialab.utilities.file_access_utilities as futil\n",
    "    import mialab.utilities.pipeline_utilities as putil\n",
    "except ImportError:\n",
    "    # Append the MIALab root directory to Python path\n",
    "    print(os.path.dirname(sys.argv[0]), '..')\n",
    "    sys.path.insert(0, '/storage/homefs/lr13y079/MIALab/MIALab-master')\n",
    "    import mialab.data.structure as structure\n",
    "    import mialab.utilities.file_access_utilities as futil\n",
    "    import mialab.utilities.pipeline_utilities as putil\n",
    "\n",
    "LOADING_KEYS = [structure.BrainImageTypes.T1w,\n",
    "                structure.BrainImageTypes.T2w,\n",
    "                structure.BrainImageTypes.GroundTruth,\n",
    "                structure.BrainImageTypes.BrainMask,\n",
    "                structure.BrainImageTypes.RegistrationTransform]  # the list of data we will load\n",
    "\n",
    "\n",
    "def main(result_dir: str, data_atlas_dir: str, data_train_dir: str, data_test_dir: str):\n",
    "    \"\"\"Brain tissue segmentation using decision forests.\n",
    "\n",
    "    The main routine executes the medical image analysis pipeline:\n",
    "\n",
    "        - Image loading\n",
    "        - Registration\n",
    "        - Pre-processing\n",
    "        - Feature extraction\n",
    "        - Decision forest classifier model building\n",
    "        - Segmentation using the decision forest classifier model on unseen images\n",
    "        - Post-processing of the segmentation\n",
    "        - Evaluation of the segmentation\n",
    "    \"\"\"\n",
    "    # all the combinations of removing one or two elements from a list of seven \n",
    "    # --> 0,1,2: atlas coordinates feature   3,4: intensity features (T1,T2)   \n",
    "    #     5,6: gradient magnitude features (T1,T2)\n",
    "    feature_to_del = [None] + list(itertools.combinations(list(range(0,7)), 2)) + list(itertools.combinations(list(range(0,7)), 1))\n",
    "   \n",
    "                   \n",
    "    \n",
    "    \n",
    "    result_dir_master = result_dir\n",
    "    print('combinations of features to delete {}'.format(feature_to_del))\n",
    "    \n",
    "    # loop over all combinations of features to delete\n",
    "    for i, fdel in enumerate(feature_to_del):\n",
    "        print('features removed: {}'.format(fdel))\n",
    "        result_dir = result_dir_master\n",
    "        \n",
    "        # load atlas images\n",
    "        putil.load_atlas_images(data_atlas_dir)\n",
    "\n",
    "        print('-' * 5, 'Training...')\n",
    "\n",
    "        # crawl the training image directories\n",
    "        crawler = futil.FileSystemDataCrawler(data_train_dir,\n",
    "                                              LOADING_KEYS,\n",
    "                                              futil.BrainImageFilePathGenerator(),\n",
    "                                              futil.DataDirectoryFilter())\n",
    "        pre_process_params = {'skullstrip_pre': True,\n",
    "                              'normalization_pre': True,\n",
    "                              'registration_pre': True,\n",
    "                              'coordinates_feature': True,\n",
    "                              'intensity_feature': True,\n",
    "                              'gradient_intensity_feature': True}\n",
    "        \n",
    "        \n",
    "        # load images for training and pre-process\n",
    "        if fdel is None:\n",
    "            images = putil.pre_process_batch(crawler.data, pre_process_params, multi_process=False)\n",
    "            with open('images_ResTimes10.pkl', 'wb') as file:\n",
    "                # A new file will be created\n",
    "                pickle.dump(images, file)\n",
    "        \n",
    "        else:\n",
    "            with open('images_ResTimes10.pkl', 'rb') as file:\n",
    "                images = pickle.load(file)\n",
    "        \n",
    "        # delete features from feature_matrices of all pre-processed training images\n",
    "        if fdel is not None:\n",
    "            for img in images:\n",
    "                img.feature_matrix = (np.delete(img.feature_matrix[0], fdel, 1), img.feature_matrix[1])\n",
    "\n",
    "        # generate feature matrix and label vector\n",
    "        data_train = np.concatenate([img.feature_matrix[0] for img in images])\n",
    "        labels_train = np.concatenate([img.feature_matrix[1] for img in images]).squeeze()\n",
    "\n",
    "        forest = sk_ensemble.RandomForestClassifier(max_features=images[0].feature_matrix[0].shape[1], n_estimators=10, max_depth=50)\n",
    "        \n",
    "        start_time = timeit.default_timer()\n",
    "        forest.fit(data_train, labels_train)\n",
    "        print(' Time elapsed:', timeit.default_timer() - start_time, 's')\n",
    "\n",
    "        # create a result directory with timestamp\n",
    "        t = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S_feature_deleted_{}'.format(fdel))\n",
    "        result_dir = os.path.join(result_dir, t)\n",
    "        os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "        print('-' * 5, 'Testing...')\n",
    "\n",
    "        # initialize evaluator\n",
    "        evaluator = putil.init_evaluator()\n",
    "\n",
    "        # crawl the training image directories\n",
    "        crawler = futil.FileSystemDataCrawler(data_test_dir,\n",
    "                                              LOADING_KEYS,\n",
    "                                              futil.BrainImageFilePathGenerator(),\n",
    "                                              futil.DataDirectoryFilter())\n",
    "        \n",
    "        # load images for testing and pre-process\n",
    "        if fdel is None:\n",
    "            pre_process_params['training'] = False\n",
    "            images_test = putil.pre_process_batch(crawler.data, pre_process_params, multi_process=False)\n",
    "            with open('images_test_ResTimes10.pkl', 'wb') as file:\n",
    "                # A new file will be created\n",
    "                pickle.dump(images_test, file)\n",
    "        \n",
    "        else:\n",
    "            with open('images_test_ResTimes10.pkl', 'rb') as file:\n",
    "                images_test = pickle.load(file)\n",
    "    \n",
    "         # delete features from feature_matrices of all pre-processed testing images\n",
    "        if fdel is not None:\n",
    "            for img in images_test:\n",
    "                img.feature_matrix = (np.delete(img.feature_matrix[0], fdel, 1), img.feature_matrix[1])\n",
    "    \n",
    "        images_prediction = []\n",
    "        images_probabilities = []\n",
    "    \n",
    "        for img in images_test:\n",
    "            print('-' * 10, 'Testing', img.id_)\n",
    "\n",
    "            start_time = timeit.default_timer()\n",
    "            predictions = forest.predict(img.feature_matrix[0])\n",
    "            probabilities = forest.predict_proba(img.feature_matrix[0])\n",
    "            print(' Time elapsed:', timeit.default_timer() - start_time, 's')\n",
    "\n",
    "            # convert prediction and probabilities back to SimpleITK images\n",
    "            image_prediction = conversion.NumpySimpleITKImageBridge.convert(predictions.astype(np.uint8),\n",
    "                                                                        img.image_properties)\n",
    "            image_probabilities = conversion.NumpySimpleITKImageBridge.convert(probabilities, img.image_properties)\n",
    "\n",
    "            # evaluate segmentation without post-processing\n",
    "            evaluator.evaluate(image_prediction, img.images[structure.BrainImageTypes.GroundTruth], img.id_)\n",
    "\n",
    "            images_prediction.append(image_prediction)\n",
    "            images_probabilities.append(image_probabilities)\n",
    "\n",
    "        # post-process segmentation and evaluate with post-processing\n",
    "        post_process_params = {'simple_post': True}\n",
    "        images_post_processed = putil.post_process_batch(images_test, images_prediction, images_probabilities,\n",
    "                                                         post_process_params, multi_process=True)\n",
    "\n",
    "        for i, img in enumerate(images_test):\n",
    "            evaluator.evaluate(images_post_processed[i], img.images[structure.BrainImageTypes.GroundTruth],\n",
    "                               img.id_ + '-PP')\n",
    "\n",
    "            # save results\n",
    "            sitk.WriteImage(images_prediction[i], os.path.join(result_dir, images_test[i].id_ + '_SEG.mha'), True)\n",
    "            sitk.WriteImage(images_post_processed[i], os.path.join(result_dir, images_test[i].id_ + '_SEG-PP.mha'), True)\n",
    "\n",
    "        # use two writers to report the results\n",
    "        os.makedirs(result_dir, exist_ok=True)  # generate result directory, if it does not exists\n",
    "        result_file = os.path.join(result_dir, 'results.csv')\n",
    "        writer.CSVWriter(result_file).write(evaluator.results)\n",
    "\n",
    "        print('\\nSubject-wise results...')\n",
    "        writer.ConsoleWriter().write(evaluator.results)\n",
    "\n",
    "        # report also mean and standard deviation among all subjects\n",
    "        result_summary_file = os.path.join(result_dir, 'results_summary.csv')\n",
    "        functions = {'MEAN': np.mean, 'STD': np.std}\n",
    "        writer.CSVStatisticsWriter(result_summary_file, functions=functions).write(evaluator.results)\n",
    "        print('\\nAggregated statistic results...')\n",
    "        writer.ConsoleStatisticsWriter(functions=functions).write(evaluator.results)\n",
    "\n",
    "        # clear results such that the evaluator is ready for the next evaluation\n",
    "        evaluator.clear()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"The program's entry point.\"\"\"\n",
    "\n",
    "    script_dir = os.path.dirname(sys.argv[0])\n",
    "    #script_dir = '/storage/homefs/lr13y079/MIALab/MIALab-master'\n",
    "    print(script_dir)\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Medical image analysis pipeline for brain tissue segmentation')\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--result_dir',\n",
    "        type=str,\n",
    "        default=os.path.normpath(os.path.join(script_dir, './mia-result')),\n",
    "        help='Directory for results.'\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--data_atlas_dir',\n",
    "        type=str,\n",
    "        default=os.path.normpath(os.path.join(script_dir, '../data/atlas')),\n",
    "        help='Directory with atlas data.'\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--data_train_dir',\n",
    "        type=str,\n",
    "        default=os.path.normpath(os.path.join(script_dir, '../data/train/')),\n",
    "        help='Directory with training data.'\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        '--data_test_dir',\n",
    "        type=str,\n",
    "        default=os.path.normpath(os.path.join(script_dir, '../data/test/')),\n",
    "        help='Directory with testing data.'\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    main(args.result_dir, args.data_atlas_dir, args.data_train_dir, args.data_test_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57761f62-be34-49ac-8035-dfb196115bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "import os\n",
    "import csv\n",
    "import itertools\n",
    "import functools\n",
    "import operator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Amygdala = np.zeros((4, 29))\n",
    "GreyMatter = np.zeros((4, 29))\n",
    "Hippocampus = np.zeros((4, 29))\n",
    "Thalamus = np.zeros((4, 29))\n",
    "WhiteMatter = np.zeros((4, 29))\n",
    "labels = ['AtlasX','AtlasY','AtlasZ','T1 Int.','T2 Int.','T1 Grad.','T2 Grad.']\n",
    "    \n",
    "\n",
    "files = sorted(os.listdir('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/increased_res_depth'))\n",
    "files = [item for item in files if any(ele in item for ele in ['2022'])]\n",
    "for idx, folder in enumerate(files):\n",
    "    path = os.path.join('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/increased_res_depth', folder, 'results_summary.csv')\n",
    "    with open(path, newline='') as csvfile:\n",
    "        reader = list(csv.reader(csvfile, delimiter=';'))\n",
    "        for n in range(4):\n",
    "            Amygdala[n][idx] = reader[n + 1][3]\n",
    "            GreyMatter[n][idx] = reader[n + 5][3]\n",
    "            Hippocampus[n][idx] = reader[n + 9][3]\n",
    "            Thalamus[n][idx] = reader[n + 13][3]\n",
    "            WhiteMatter[n][idx] = reader[n + 17][3]\n",
    "\n",
    "Amygdala[0][1:29] = 1 - Amygdala[0][1:29] / Amygdala[0][0] \n",
    "GreyMatter[0][1:29] = 1 - GreyMatter[0][1:29] / GreyMatter[0][0]\n",
    "Hippocampus[0][1:29] = 1 - Hippocampus[0][1:29] / Hippocampus[0][0]\n",
    "Thalamus[0][1:29] = 1 - Thalamus[0][1:29] / Thalamus[0][0]\n",
    "WhiteMatter[0][1:29] = 1 - WhiteMatter[0][1:29] / WhiteMatter[0][0]\n",
    "Amygdala[2][1:29] = 1 - Amygdala[2][1:29] / Amygdala[2][0] \n",
    "GreyMatter[2][1:29] = 1 - GreyMatter[2][1:29] / GreyMatter[2][0]\n",
    "Hippocampus[2][1:29] = 1 - Hippocampus[2][1:29] / Hippocampus[2][0]\n",
    "Thalamus[2][1:29] = 1 - Thalamus[2][1:29] / Thalamus[2][0]\n",
    "WhiteMatter[2][1:29] = 1 - WhiteMatter[2][1:29] / WhiteMatter[2][0]\n",
    "\n",
    "SmallRegions = (Amygdala + Hippocampus + Thalamus) / 3\n",
    "LargeRegions = (WhiteMatter + GreyMatter) / 2\n",
    "\n",
    "   \n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.rcParams[\"figure.figsize\"] = (10*np.sqrt(2), 10)\n",
    "plt.errorbar(range(28), -SmallRegions[0][1:29], yerr=SmallRegions[1][1:29], fmt='o', label='Small Regions')\n",
    "plt.errorbar(range(28), -LargeRegions[0][1:29], yerr=LargeRegions[1][1:29], fmt='o', label='Large Regions')\n",
    "plt.legend(loc='lower right', fontsize=20)\n",
    "plt.xticks(range(0,28), rotation=90)\n",
    "ax.set_xticklabels(list(itertools.combinations(labels, 2)) + list(itertools.combinations(labels, 1)))\n",
    "#plt.title('DICE')\n",
    "plt.ylabel('percentage DICE drop', fontsize=20)\n",
    "plt.grid(which='major', axis='both')\n",
    "#ax.invert_xaxis()\n",
    "plt.savefig('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/increased_res_depth/DICE2.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.rcParams[\"figure.figsize\"] = (10*np.sqrt(2), 10)\n",
    "plt.errorbar(Amygdala[2][1:29], range(28), xerr=Amygdala[3][1:29], fmt='o', label='Amygdala')\n",
    "plt.errorbar(GreyMatter[2][1:29], range(28), xerr=GreyMatter[3][1:29], fmt='o', label='GreyMatter')\n",
    "plt.errorbar(Hippocampus[2][1:29], range(28), xerr=Hippocampus[3][1:29], fmt='o', label='Hippocampus')\n",
    "plt.errorbar(Thalamus[2][1:29], range(28), xerr=Thalamus[3][1:29], fmt='o', label='Thalamus')\n",
    "plt.errorbar(WhiteMatter[2][1:29], range(28), xerr=WhiteMatter[3][1:29], fmt='o', label='WhiteMatter')\n",
    "plt.legend(loc='upper right')\n",
    "plt.yticks(range(0,28))\n",
    "ax.set_yticklabels(list(itertools.combinations(labels, 2)) + list(itertools.combinations(labels, 1)))\n",
    "plt.title('HD')\n",
    "plt.grid(which='major', axis='both')\n",
    "#plt.savefig('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/increased_res_depth/HD.pdf', bbox_inches='tight')\n",
    "plt.show()          \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e540ce9d-3da7-4e6d-821d-8845685b33e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplots\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def readcsv(path):\n",
    "    data = pd.read_csv(path)\n",
    "    data = data.values.tolist()\n",
    "\n",
    "    results = []\n",
    "    for i in range(len(data)):\n",
    "        a = data[i]\n",
    "        a = a[0].split(';')\n",
    "        results.append(a)\n",
    "\n",
    "    DICE = np.zeros((math.floor(len(data)/5),5))\n",
    "    HD = np.zeros((math.floor(len(data)/5),5))\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        DICE[math.floor(i/5)][i%5] = results[i][2]\n",
    "        HD[math.floor(i/5)][i%5] = results[i][3]\n",
    "    return DICE, HD\n",
    "\n",
    "def main():\n",
    "    # todo: load the \"results.csv\" file from the mia-results directory\n",
    "    # todo: read the data into a list\n",
    "    # todo: plot the Dice coefficients per label (i.e. white matter, gray matter, hippocampus, amygdala, thalamus)\n",
    "    #  in a boxplot\n",
    "\n",
    "    # alternative: instead of manually loading/reading the csv file you could also use the pandas package\n",
    "    # but you will need to install it first ('pip install pandas') and import it to this file ('import pandas as pd')\n",
    "\n",
    "\n",
    "\n",
    "    DICE, HD = readcsv('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/increased_res_depth/2022-11-10-04-58-11_feature_deleted_None/results.csv')\n",
    "    DICE = np.transpose(DICE)\n",
    "    HD = np.transpose(HD)\n",
    "    DICEatlas, HDatlas = readcsv('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/atlas_only/results.csv')\n",
    "    DICEatlas = np.transpose(DICEatlas)\n",
    "    HDatlas = np.transpose(HDatlas)\n",
    "    DICEint, HDint = readcsv('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/intensity_only/results.csv')\n",
    "    DICEint = np.transpose(DICEint)\n",
    "    HDint = np.transpose(HDint)\n",
    "    DICEgrad, HDgrad = readcsv('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/gradient_only/results.csv')\n",
    "    DICEgrad = np.transpose(DICEgrad)\n",
    "    HDgrad = np.transpose(HDgrad)\n",
    "    \n",
    "    fig1, ax = plt.subplots()\n",
    "    plt.rcParams[\"figure.figsize\"] = (8,5)\n",
    "    ax.set_title('Amygdala')\n",
    "    ax.boxplot([DICE[0], DICEatlas[0], DICEint[0], DICEgrad[0]])\n",
    "    plt.ylim([0, 0.9])\n",
    "    plt.xticks([1, 2, 3, 4], ['All features', 'Atlas only', 'Intensity only', 'Gradient only'])\n",
    "    plt.savefig('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/DICE_Amygdala.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    fig2, ax = plt.subplots()\n",
    "    ax.set_title('HD Amygdala')\n",
    "    ax.boxplot([HD[0], HDatlas[0], HDint[0], HDgrad[0]])\n",
    "    plt.xticks([1, 2, 3, 4], ['All features', 'Atlas only', 'Intensity only', 'Gradient only'])\n",
    "    plt.savefig('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/HD_Amygdala.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    fig3, ax = plt.subplots()\n",
    "    ax.set_title('GreyMatter')\n",
    "    ax.boxplot([DICE[1], DICEatlas[1], DICEint[1], DICEgrad[1]])\n",
    "    plt.ylim([0, 0.9])\n",
    "    plt.xticks([1, 2, 3, 4], ['All features', 'Atlas only', 'Intensity only', 'Gradient only'])\n",
    "    plt.savefig('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/DICE_GreyMatter.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    fig4, ax = plt.subplots()\n",
    "    ax.set_title('HD GreyMatter')\n",
    "    ax.boxplot([HD[1], HDatlas[1], HDint[1], HDgrad[1]])\n",
    "    \n",
    "    plt.xticks([1, 2, 3, 4], ['All features', 'Atlas only', 'Intensity only', 'Gradient only'])\n",
    "    plt.savefig('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/HD_GreyMatter.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    fig5, ax = plt.subplots()\n",
    "    ax.set_title('Hippocampus')\n",
    "    ax.boxplot([DICE[2], DICEatlas[2], DICEint[2], DICEgrad[2]])\n",
    "    plt.ylim([0, 0.9])\n",
    "    plt.xticks([1, 2, 3, 4], ['All features', 'Atlas only', 'Intensity only', 'Gradient only'])\n",
    "    plt.savefig('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/DICE_Hippocampus.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    fig6, ax = plt.subplots()\n",
    "    ax.set_title('HD Hippocampus')\n",
    "    ax.boxplot([HD[2], HDatlas[2], HDint[2], HDgrad[2]])\n",
    "    plt.xticks([1, 2, 3, 4], ['All features', 'Atlas only', 'Intensity only', 'Gradient only'])\n",
    "    plt.savefig('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/HD_Hippocampus.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    fig7, ax = plt.subplots()\n",
    "    ax.set_title('Thalamus')\n",
    "    ax.boxplot([DICE[3], DICEatlas[3], DICEint[3], DICEgrad[3]])\n",
    "    plt.ylim([0, 0.9])\n",
    "    plt.xticks([1, 2, 3, 4], ['All features', 'Atlas only', 'Intensity only', 'Gradient only'])\n",
    "    plt.savefig('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/DICE_Thalamus.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    fig8, ax = plt.subplots()\n",
    "    ax.set_title('HD Thalamus')\n",
    "    ax.boxplot([HD[3], HDatlas[3], HDint[3], HDgrad[3]])\n",
    "    plt.xticks([1, 2, 3, 4], ['All features', 'Atlas only', 'Intensity only', 'Gradient only'])\n",
    "    plt.savefig('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/HD_Thalamus.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    fig9, ax = plt.subplots()\n",
    "    ax.set_title('WhiteMatter')\n",
    "    ax.boxplot([DICE[4], DICEatlas[4], DICEint[4], DICEgrad[4]])\n",
    "    plt.ylim([0, 0.9])\n",
    "    plt.xticks([1, 2, 3, 4], ['All features', 'Atlas only', 'Intensity only', 'Gradient only'])\n",
    "    plt.savefig('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/DICE_WhiteMatter.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    fig10, ax = plt.subplots()\n",
    "    ax.set_title('HD WhiteMatter')\n",
    "    ax.boxplot([HD[4], HDatlas[4], HDint[4], HDgrad[4]])\n",
    "    plt.xticks([1, 2, 3, 4], ['All features', 'Atlas only', 'Intensity only', 'Gradient only'])\n",
    "    plt.savefig('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/HD_whiteMatter.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "                \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef044327-2051-47a4-b674-a4f1e64e4f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "import os\n",
    "import csv\n",
    "import itertools\n",
    "import functools\n",
    "import operator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Amygdala = np.zeros((4, 10))\n",
    "GreyMatter = np.zeros((4, 10))\n",
    "Hippocampus = np.zeros((4, 10))\n",
    "Thalamus = np.zeros((4, 10))\n",
    "WhiteMatter = np.zeros((4, 10))\n",
    "\n",
    "labels = ['AtlasX','AtlasY','AtlasZ','T1 Int.','T2 Int.','T1 Grad.','T2 Grad.']\n",
    "    \n",
    "\n",
    "files = sorted(os.listdir('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/depth_variations'))\n",
    "print(files)\n",
    "files = [item for item in files if any(ele in item for ele in ['0','9'])]\n",
    "for idx, folder in enumerate(files):\n",
    "    path = os.path.join('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/depth_variations', folder, 'results_summary.csv')\n",
    "    with open(path, newline='') as csvfile:\n",
    "        reader = list(csv.reader(csvfile, delimiter=';'))\n",
    "        for n in range(4):\n",
    "            Amygdala[n][idx] = reader[n + 1][3]\n",
    "            GreyMatter[n][idx] = reader[n + 5][3]\n",
    "            Hippocampus[n][idx] = reader[n + 9][3]\n",
    "            Thalamus[n][idx] = reader[n + 13][3]\n",
    "            WhiteMatter[n][idx] = reader[n + 17][3]\n",
    "        \n",
    "SmallRegions = (Amygdala + Hippocampus + Thalamus)/3\n",
    "LargeRegions = (WhiteMatter + GreyMatter)/2\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "plt.errorbar(range(10), Amygdala[0][0:10], yerr=Amygdala[1][0:10], label='Amygdala')\n",
    "plt.errorbar(range(10), GreyMatter[0][0:10], yerr=GreyMatter[1][0:10], label='GreyMatter')\n",
    "plt.errorbar(range(10), Hippocampus[0][0:10], yerr=Hippocampus[1][0:10], label='Hippocampus')\n",
    "plt.errorbar(range(10), Thalamus[0][0:10], yerr=Thalamus[1][0:10], label='Thalamus')\n",
    "plt.errorbar(range(10), WhiteMatter[0][0:10], yerr=WhiteMatter[1][0:10], label='WhiteMatter')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xticks(range(0,10))\n",
    "ax.set_xticklabels([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "plt.title('DICE')\n",
    "#plt.grid(which='major', axis='both')\n",
    "#ax.invert_xaxis()\n",
    "plt.xlabel('tree depth')\n",
    "plt.savefig('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/depth_variations/DICE.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "plt.errorbar(range(10), Amygdala[2][0:10], yerr=Amygdala[3][0:10], label='Amygdala')\n",
    "plt.errorbar(range(10), GreyMatter[2][0:10], yerr=GreyMatter[3][0:10], label='GreyMatter')\n",
    "plt.errorbar(range(10), Hippocampus[2][0:10], yerr=Hippocampus[3][0:10], label='Hippocampus')\n",
    "plt.errorbar(range(10), Thalamus[2][0:10], yerr=Thalamus[3][0:10], label='Thalamus')\n",
    "plt.errorbar(range(10), WhiteMatter[2][0:10], yerr=WhiteMatter[3][0:10], label='WhiteMatter')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xticks(range(0,10))\n",
    "ax.set_xticklabels([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "plt.title('HD')\n",
    "#plt.grid(which='major', axis='both')\n",
    "plt.xlabel('tree depth')\n",
    "plt.savefig('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/depth_variations/HD.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "'''         \n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "plt.errorbar(range(10), SmallRegions[0][0:10], yerr=SmallRegions[1][0:10], label='Small Regions')\n",
    "plt.errorbar(range(10), LargeRegions[0][0:10], yerr=LargeRegions[1][0:10], label='Large Regions')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xticks(range(0,10))\n",
    "ax.set_xticklabels([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "plt.title('DICE')\n",
    "#plt.grid(which='major', axis='both')\n",
    "#ax.invert_xaxis()\n",
    "plt.xlabel('tree depth')\n",
    "plt.savefig('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/depth_variations/DICE.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "plt.errorbar(range(10), SmallRegions[2][0:10], yerr=SmallRegions[3][0:10], label='Small Regions')\n",
    "plt.errorbar(range(10), LargeRegions[2][0:10], yerr=LargeRegions[3][0:10], label='Large Regions')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xticks(range(0,10))\n",
    "ax.set_xticklabels([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "plt.title('HD')\n",
    "#plt.grid(which='major', axis='both')\n",
    "plt.xlabel('tree depth')\n",
    "plt.savefig('/storage/homefs/lr13y079/MIALab/MIALab-master/bin/mia-result/depth_variations/HD.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72d7469-f420-44d4-8646-d596bc778e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
